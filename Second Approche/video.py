# -*- coding: utf-8 -*-
"""Video.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_0l2IkCIOjn1CWb7VaQEYujyezb0crnm
"""

!git clone  https://github.com/cristinalunaj/MMEmotionRecognition.git

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install datasets
# !pip install transformers wandb 
#

# Commented out IPython magic to ensure Python compatibility.
# %cd MMEmotionRecognition/

!pwd

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !wget https://zenodo.org/record/1188976/files/Video_Speech_Actor_01.zip?download=1

!unzip /content/MMEmotionRecognition/Video_Speech_Actor_01.zip?download=1

import argparse

parser = argparse.ArgumentParser(description="Configuration of setup and training process")
parser.add_argument('-videos', '--videos_dir', type=str,  default="./Actor_01",
                    help='Path with the embeddings to train/test the models')
parser.add_argument('-out', '--out_dir', type=str,
                    help='Path to save the AUs & additional material generated by the OpenFace library',
                    default='./Video/OpenFaceGeneration')
parser.add_argument('-outProcessed', '--out_dir_processed', type=str,
                    help='Path to save the AUs extracted from OpenFace after processing them',
                    default='./Video/OpenFaceAU')
parser.add_argument('-openFace', '--openFace_path', type=str,  default="/content/OpenFace",
                    help='Path where you have installed/downloaded the OpenFace library')
args = parser.parse_args(args=[])
args

"""##Installation OpenFace"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# import os
# from os.path import exists, join, basename, splitext
# 
# ################# Need to revert back to CUDA 10.0 ##################
# # Thanks to http://aconcaguasci.blogspot.com/2019/12/setting-up-cuda-100-for-mxnet-on-google.html
# #Uninstall the current CUDA version
# !apt-get --purge remove cuda nvidia* libnvidia-*
# !dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge
# !apt-get remove cuda-*
# !apt autoremove
# !apt-get update
# 
# #Download CUDA 10.0
# !wget  --no-clobber https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
# #install CUDA kit dpkg
# !dpkg -i -y cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
# !sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
# !apt-get update
# !apt-get install cuda-10-0
# #Slove libcurand.so.10 error
# !wget --no-clobber http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
# #-nc, --no-clobber: skip downloads that would download to existing files.
# !apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
# !apt-get update
# ####################################################################
# 
# git_repo_url = 'https://github.com/TadasBaltrusaitis/OpenFace.git'
# project_name = splitext(basename(git_repo_url))[0]
# # clone openface
# !git clone -q --depth 1 $git_repo_url
# 
# # install new CMake becaue of CUDA10
# !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz
# !tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local
# 
# # Get newest GCC
# !sudo apt-get update
# !sudo apt-get install build-essential 
# !sudo apt-get install g++-8
# 
# # install python dependencies
# !pip install -q youtube-dl
# 
# # Finally, actually install OpenFace
# !cd OpenFace && bash ./download_models.sh && sudo bash ./install.sh

from src.Video.OpenFace.AUsFeatureExtractor import *

def extract_features_OpenFace(video_name, in_root_videos, path_installed_openFace, out_path, static=" -au_static"):
    """
        Generate AUs using the OpenFace library

        :param video_name:[str] Name of the video to process
        :param: in_root_videos [str]: Path to the folder that contains all the videos to process
        :param: path_installed_openFace [str]: Path to the folder whwere we installed OpenFace
        :param out_path[str]: Path to save the AUs and extra material generated by OpenFace
        :param static[str]: au_static flag tells OpenFace not to perform dynamic calibration and to use only static models for AU prediction (see: https://github.com/TadasBaltrusaitis/OpenFace/wiki/Action-Units)

    """
    out_path_video = os.path.join(out_path, video_name.split(".")[0])
    os.makedirs(out_path_video, exist_ok=True)
    video_path = os.path.join(in_root_videos, video_name)
    command = os.path.join(path_installed_openFace, "build", "bin", "FeatureExtraction")+ static + " -f "+video_path+" -out_dir "+out_path_video
    os.system(command)
    
os.makedirs(args.out_dir_processed, exist_ok=True)
for video in os.listdir(args.videos_dir):
    extract_features_OpenFace(video, args.videos_dir, args.openFace_path, args.out_dir, static="")
save_embs_complete(args.out_dir, args.out_dir_processed)

from src.Video.OpenFace.AUsFeatureExtractor import *

def save_embs_complete(path_folder_OpenFace, out_path_embs):
    """
       Save Dataframes with only the AUs columns
        :param path_folder_OpenFace:[str] Path where the AUs wehre saved during the extraction process of OpenFace
        :param: out_path_embs [str]: Path to the save the new Dataframes generated that only contains onformation ofthe AUs.
    """
    cols2select = ["AU01_r" ,"AU02_r" ,"AU04_r" , "AU05_r","AU06_r", "AU07_r", "AU09_r", "AU10_r","AU12_r","AU14_r","AU15_r", "AU17_r", "AU20_r", "AU23_r", "AU25_r", "AU26_r", "AU45_r", "AU01_c", "AU02_c", "AU04_c" ,"AU05_c", "AU06_c", "AU07_c", "AU09_c", "AU10_c", "AU12_c", "AU14_c", "AU15_c", "AU17_c", "AU20_c", "AU23_c", "AU25_c", "AU26_c", "AU28_c", "AU45_c"]
    for video_folder in os.listdir(path_folder_OpenFace):
        path_AU = os.path.join(path_folder_OpenFace, video_folder, video_folder+".csv")
        df_aus = pd.read_csv(path_AU, ",")
        df_aux = df_aus[cols2select]
        print(video_folder)
        df_aux.to_csv(os.path.join(out_path_embs, video_folder+".csv"), sep=";", header=True, index=False)


save_embs_complete(args.out_dir, args.out_dir_processed)

"""##Training """

!unzip /content/MMEmotionRecognition/Video/OpenFaceAU.zip

parser = argparse.ArgumentParser(description="Configuration of setup and training process")
parser.add_argument('-AUs', '--AUs_dir', type=str, default="/content/MMEmotionRecognition/Video/OpenFaceAU",
                    help='Path with the embeddings to train/test the models')
parser.add_argument('-out', '--out_dir', type=str, help='Path to save the posteriors of the train and test sets after trainig each model',
                    default="./video")
parser.add_argument('-m', '--model_number', type=int, default=2,
                    help='1-SVC / 2- Logistic Regression / 3- ridgeClassifier /4-perceptron / 5-NuSVC / 6-LinearSVC / 7-knn / 8-NearestCentroid / 9- DecrissionTree / 10- RandomForest / 11 - MLP')
parser.add_argument('-modelParam', '--param', type=str, default="C",
                    help='Parameter of the model: C for SVC / C Logistic Regression / alpha in ridgeClassifier / alpha in perceptron / nu in NuSVC / C in LinearSVC / k in knn / None in NearestCentroid / min_samples_split in DecrissionTree / n_estimators in RandomForest / hidden_layer_sizes in MLP')
parser.add_argument('-norm', '--type_of_norm', type=int, default=2,
                    help='0-MinMax Norm / 1-Standard Norm / 2- No apply normalization [default: 2]')

args = parser.parse_args(args=[])
args

from src.Video.models.staticModels.FeatureTrainingAUs import *
import argparse
import os.path, os, sys
import argparse
sys.path.append('.')
sys.path.append('..')
sys.path.append('../../')
sys.path.append('../../../')

def process_AUs_avg(embs_path, avg_embs_path):
    """
           Save Dataframes with only the AUs columns
            :param embs_path:[str] Path where the processed AUs where saved after the extraction process of OpenFace. This embeddings has dimension (35,timesteps)
            :param: avg_embs_path [str]:  Path to save the average AUs calculated collapsing the timesteps. This embeddings has dimension (35,1)
        """
    if (os.path.exists(avg_embs_path)):
        X_total = pd.read_csv(avg_embs_path, sep=";", header=0)
    else:
        X_total = pd.DataFrame([])
        for video_embs in os.listdir(embs_path):
            embs_df = pd.read_csv(os.path.join(embs_path, video_embs), sep=";", header=0)

            aux_df = pd.DataFrame([embs_df.mean()], columns=embs_df.columns)
            aux_df["name"] = video_embs.split(".")[0]
            aux_df["path"] = video_embs.split(".")[0]
            aux_df["index"] = 0
            X_total = X_total.append(aux_df)
        X_total.to_csv(avg_embs_path, sep=";", header=True, index=False)

    X_total = X_total.rename(columns={"name":"video_name"})
    #X_total = X_total.drop(["speech"], axis=1)
    X_total["index"] = 0
    X_total["path"] = ""
    X_total["actor"] = pd.to_numeric(X_total["video_name"].str.replace(".csv", "").str.split('-').str[-1])
    X_total["emotion"] = pd.to_numeric(X_total["video_name"].str.split('-').str[2])
    X_total["emotion"]-=1
    return X_total


seed = 2020
avg_embs_path = os.path.join(args.AUs_dir.rsplit("/", 1)[0], "df_average_AUs_total.csv")

get_embs = True
os.makedirs(args.out_dir, exist_ok=True)

# Get average:
X_total = process_AUs_avg(args.AUs_dir, avg_embs_path)
print(X_total)

avg_embs_path

args.AUs_dir

"""##Sequentiel Models

#
"""

parser = argparse.ArgumentParser(description="Configuration of setup and training process")
parser.add_argument('-AUs', '--AUs_dir', type=str, default='./Video/OpenFaceAU',
                    help='Path with the embeddings to train/test the models')
parser.add_argument('-out', '--out_dir', type=str,
                    help='Path to save the AUs & additional material generated by the OpenFace library',
                    default='./AU_Extraction')
args = parser.parse_args(args=[])
args

import sys
import argparse
import os
sys.path.append('.')
sys.path.append('..')
sys.path.append('../../')
sys.path.append('../../../')
from src.Video.models.sequenceLearning.frontend.RAVDESS_AUs.frontend_ravdess_5CV import get_fold ,create_training_validation_df ,create_complete_dataset

os.makedirs(args.out_dir, exist_ok=True)
out_path_ds = os.path.join(args.out_dir, "complete_dataset_5CV.txt")
formatting = lambda x: '{:05d}'.format(x)

dict_actors_in_test_per_fold = {
    1: [1,11],

}

dict_emotions = {0: "neutral", 1: "calm", 2: "happy", 3: "sad", 4:"angry", 5:"fear", 6:"disgust", 7: "surprise"}

if(os.path.exists(out_path_ds)):
    #If complete dataset, load it:
    df_complete_ds = pd.read_csv(out_path_ds, sep='\t', header=None)
    df_complete_ds.columns = ["sample_number", "label", "path_data", "sample_id", "test_fold"]
    df_complete_ds["sample_number"] = df_complete_ds["sample_number"].apply(formatting)
else:
    df_complete_ds = create_complete_dataset(args.AUs_dir, dict_actors_in_test_per_fold, dict_emotions,out_path_ds, formatting)

#Create training-validation per fold
for fold_i in list(dict_actors_in_test_per_fold.keys()):
    train_df_foldi, test_df_foldi = create_training_validation_df(df_complete_ds, fold_i)
    #save dataframes:
    train_df_foldi.to_csv(os.path.join(args.out_dir, "training-fold_"+str(fold_i)+"_outof_"+str(len(dict_actors_in_test_per_fold.keys()))+".txt"),
                          index=False, header=None, sep='\t')
    test_df_foldi.to_csv(os.path.join(args.out_dir, "validation-fold_" + str(fold_i) + "_outof_" + str(
        len(dict_actors_in_test_per_fold.keys())) + ".txt"),
                          index=False, header=None, sep='\t')